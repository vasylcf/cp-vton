{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:48.048319Z",
     "start_time": "2020-06-25T09:43:47.706523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 25 09:43:47 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 980     Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 37%   42C    P0    35W / 180W |      0MiB /  4043MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Quadro K2200        Off  | 00000000:05:00.0 Off |                  N/A |\r\n",
      "| 42%   40C    P8     1W /  39W |   3967MiB /  4041MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1     16594      C   python                                      3955MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.Background  \n",
    "1.Hat  \n",
    "2.Hair  \n",
    "3.Glove  \n",
    "4.Sunglasses  \n",
    "5.UpperClothes  \n",
    "6.Dress  \n",
    "7.Coat  \n",
    "8.Socks  \n",
    "9.Pants  \n",
    "10.Torso-skin  \n",
    "11.Scarf  \n",
    "12.Skirt  \n",
    "13.Face  \n",
    "14.Left-arm  \n",
    "15.Right-arm  \n",
    "16.Left-leg  \n",
    "17.Right-leg  \n",
    "18.Left-shoe  \n",
    "19.Right-shoe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:48.099422Z",
     "start_time": "2020-06-25T09:43:48.053944Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.172595Z",
     "start_time": "2020-06-25T09:43:48.100659Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "from tensorflow.keras import callbacks\n",
    "from keras_radam import RAdam\n",
    "\n",
    "import albumentations as albu\n",
    "\n",
    "import cv2\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.175483Z",
     "start_time": "2020-06-25T09:43:49.173724Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.187675Z",
     "start_time": "2020-06-25T09:43:49.176179Z"
    }
   },
   "outputs": [],
   "source": [
    "sm.set_framework('tf.keras')\n",
    "\n",
    "BACKBONE = 'resnet50'\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.192308Z",
     "start_time": "2020-06-25T09:43:49.188447Z"
    }
   },
   "outputs": [],
   "source": [
    "root_path = '.'\n",
    "checkpoints_path = f'{root_path}/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.197099Z",
     "start_time": "2020-06-25T09:43:49.193158Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.201834Z",
     "start_time": "2020-06-25T09:43:49.198434Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.206847Z",
     "start_time": "2020-06-25T09:43:49.202711Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = '/work/develop/datasets/LIP/CIHP/instance-level_human_parsing'\n",
    "\n",
    "train_images_path = f'{dataset_path}/Training/Images'\n",
    "train_id_path = f'{dataset_path}/Training/train_id.txt'\n",
    "train_categories_path = f'{dataset_path}/Training/Category_ids'\n",
    "\n",
    "valid_images_path = f'{dataset_path}/Validation/Images'\n",
    "valid_categories_path = f'{dataset_path}/Validation/Category_ids'\n",
    "valid_id_path = f'{dataset_path}/Validation/val_id.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.211861Z",
     "start_time": "2020-06-25T09:43:49.207560Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preprocessing(preprocessing_fn):\n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "    ]\n",
    "    \n",
    "    return albu.Compose(_transform)\n",
    "\n",
    "def get_train_augmentations():\n",
    "    _transform = [\n",
    "#         albu.VerticalFlip(), \n",
    "        albu.HorizontalFlip(), \n",
    "        albu.ShiftScaleRotate(scale_limit=0.1, rotate_limit=10, shift_limit=0.05, border_mode=0), \n",
    "        albu.RandomBrightnessContrast(),\n",
    "        albu.RandomContrast(),\n",
    "        # albu.GridDistortion(num_steps=2),\n",
    "#         albu.Blur(blur_limit=3)\n",
    "    ]\n",
    "    \n",
    "    return albu.Compose(_transform, p=0.5)  # probabilty of tranformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.221418Z",
     "start_time": "2020-06-25T09:43:49.212702Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, usage, batch_size, num_classes, preprocessing=None, augmentation=None):\n",
    "        self.usage = usage\n",
    "\n",
    "        if usage == 'train':\n",
    "            id_file = train_id_path\n",
    "            self.images_folder = train_images_path\n",
    "            self.categories_folder = train_categories_path\n",
    "        else:\n",
    "            id_file = valid_id_path\n",
    "            self.images_folder = valid_images_path\n",
    "            self.categories_folder = valid_categories_path\n",
    "            \n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.preprocessing = preprocessing\n",
    "        self.augmentation = augmentation\n",
    "        \n",
    "        with open(id_file, 'r') as f:\n",
    "            self.names = f.read().splitlines()\n",
    "\n",
    "        np.random.shuffle(self.names)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.names) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = idx * self.batch_size\n",
    "        \n",
    "        img_rows, img_cols = 224, 224\n",
    "\n",
    "        length = min(self.batch_size, (len(self.names) - i))\n",
    "        batch_x = np.empty((length, img_rows, img_cols, 3), dtype=np.float32)\n",
    "        batch_y = np.empty((length, img_rows, img_cols, self.num_classes), dtype=np.float32)\n",
    "\n",
    "        for i_batch in range(length):\n",
    "            name = self.names[i]\n",
    "            filename = os.path.join(self.images_folder, name + '.jpg')\n",
    "            image = cv2.cvtColor(cv2.imread(filename), cv2.COLOR_BGR2RGB)\n",
    "            image_size = image.shape[:2]\n",
    "            category = self.__get_category(self.categories_folder, name)\n",
    "\n",
    "            image = cv2.resize(image, (img_rows, img_cols))\n",
    "            category = cv2.resize(category, (img_rows, img_cols))\n",
    "        \n",
    "            if self.augmentation:\n",
    "                augmented = self.augmentation(image=image, mask=category)\n",
    "                image = augmented['image']\n",
    "                category = augmented['mask']\n",
    "        \n",
    "            if self.preprocessing:\n",
    "                preprocessed = self.preprocessing(image=image)\n",
    "                image = preprocessed['image']\n",
    "\n",
    "            batch_x[i_batch, :, :, 0:3] = image\n",
    "            batch_y[i_batch, :, :] = to_categorical(category, self.num_classes)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def __get_category(self, categories_folder, name):\n",
    "        filename = os.path.join(categories_folder, name + '.png')\n",
    "        semantic = cv2.imread(filename, 0)\n",
    "        return semantic\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.233931Z",
     "start_time": "2020-06-25T09:43:49.222183Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "data_generator_train = DataGenerator('train', BATCH_SIZE, num_classes, get_preprocessing(preprocess_input), get_train_augmentations())\n",
    "data_generator_valid = DataGenerator('valid', BATCH_SIZE, num_classes, get_preprocessing(preprocess_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.238805Z",
     "start_time": "2020-06-25T09:43:49.234856Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.243695Z",
     "start_time": "2020-06-25T09:43:49.239753Z"
    }
   },
   "outputs": [],
   "source": [
    "timestamp = f'{datetime.datetime.now():%Y%m%d%H%M}'\n",
    "prefix = f'{timestamp}_{learning_rate}_{BACKBONE}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:49.250216Z",
     "start_time": "2020-06-25T09:43:49.244696Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_iou_train_weights = callbacks.ModelCheckpoint(filepath=f'{checkpoints_path}/{prefix}_iou_train_weights.hdf5', mode='max', monitor='iou_score', verbose=2, save_best_only=True, save_weights_only=True)\n",
    "checkpoint_iou_val_weights = callbacks.ModelCheckpoint(filepath=f'{checkpoints_path}/{prefix}_iou_val_weights.hdf5', mode='max', monitor='val_iou_score', verbose=2, save_best_only=True, save_weights_only=True)\n",
    "checkpoint_loss_train_weights = callbacks.ModelCheckpoint(filepath=f'{checkpoints_path}/{prefix}_loss_train_weights.hdf5', mode='min', monitor='loss', verbose=2, save_best_only=True, save_weights_only=True)\n",
    "checkpoint_loss_val_weights = callbacks.ModelCheckpoint(filepath=f'{checkpoints_path}/{prefix}_loss_val_weights.hdf5', mode='min', monitor='val_loss', verbose=2, save_best_only=True, save_weights_only=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='min', min_delta=0.001, cooldown=0, min_lr=1e-5)\n",
    "# early_stopping = callbacks.EarlyStopping(monitor='val_iou_score', min_delta=0.0001, patience=15, verbose=1, mode='auto', baseline=0.95, restore_best_weights=False)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "callbacks_list = [checkpoint_iou_train_weights, checkpoint_iou_val_weights, checkpoint_loss_train_weights, checkpoint_loss_val_weights, reduce_lr, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:55.147532Z",
     "start_time": "2020-06-25T09:43:49.251299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/arsh/miniconda3/envs/gamescore_extraction/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = sm.Unet(BACKBONE, input_shape=(224, 224, 3), classes=num_classes, activation='softmax', encoder_weights='imagenet')\n",
    "model.load_weights(f'{checkpoints_path}/202006241823_0.001_resnet50_loss_val_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T09:43:55.200480Z",
     "start_time": "2020-06-25T09:43:55.148296Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=RAdam(learning_rate=learning_rate, weight_decay=0.0001, warmup_proportion=0.1, min_lr=1e-5),\n",
    "    loss=sm.losses.cce_jaccard_loss,\n",
    "    metrics=[sm.metrics.iou_score],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-25T09:43:46.292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From /home/arsh/miniconda3/envs/gamescore_extraction/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "7069/7070 [============================>.] - ETA: 0s - loss: 0.6694 - iou_score: 0.3651Epoch 1/30\n",
      "1249/7070 [====>.........................] - ETA: 4:39 - loss: 0.6952 - iou_score: 0.3438\n",
      "Epoch 00001: iou_score improved from -inf to 0.36512, saving model to ./checkpoints/202006250943_0.001_resnet50_iou_train_weights.hdf5\n",
      "\n",
      "Epoch 00001: val_iou_score improved from -inf to 0.34380, saving model to ./checkpoints/202006250943_0.001_resnet50_iou_val_weights.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.66941, saving model to ./checkpoints/202006250943_0.001_resnet50_loss_train_weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69527, saving model to ./checkpoints/202006250943_0.001_resnet50_loss_val_weights.hdf5\n",
      "7070/7070 [==============================] - 1619s 229ms/step - loss: 0.6694 - iou_score: 0.3651 - val_loss: 0.6953 - val_iou_score: 0.3438\n",
      "Epoch 2/30\n",
      "7069/7070 [============================>.] - ETA: 0s - loss: 0.6763 - iou_score: 0.3591Epoch 1/30\n",
      "1250/7070 [====>.........................] - ETA: 4:31 - loss: 0.6980 - iou_score: 0.3410\n",
      "Epoch 00002: iou_score did not improve from 0.36512\n",
      "\n",
      "Epoch 00002: val_iou_score did not improve from 0.34380\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.66941\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69527\n",
      "7070/7070 [==============================] - 1551s 219ms/step - loss: 0.6763 - iou_score: 0.3591 - val_loss: 0.6980 - val_iou_score: 0.3410\n",
      "Epoch 3/30\n",
      "7069/7070 [============================>.] - ETA: 0s - loss: 0.6753 - iou_score: 0.3600Epoch 1/30\n",
      "1249/7070 [====>.........................] - ETA: 4:29 - loss: 0.6937 - iou_score: 0.3452\n",
      "Epoch 00003: iou_score did not improve from 0.36512\n",
      "\n",
      "Epoch 00003: val_iou_score improved from 0.34380 to 0.34529, saving model to ./checkpoints/202006250943_0.001_resnet50_iou_val_weights.hdf5\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.66941\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69527 to 0.69364, saving model to ./checkpoints/202006250943_0.001_resnet50_loss_val_weights.hdf5\n",
      "7070/7070 [==============================] - 1573s 222ms/step - loss: 0.6753 - iou_score: 0.3600 - val_loss: 0.6936 - val_iou_score: 0.3453\n",
      "Epoch 4/30\n",
      "7069/7070 [============================>.] - ETA: 0s - loss: 0.6749 - iou_score: 0.3604Epoch 1/30\n",
      "1250/7070 [====>.........................] - ETA: 4:30 - loss: 0.6993 - iou_score: 0.3410\n",
      "Epoch 00004: iou_score did not improve from 0.36512\n",
      "\n",
      "Epoch 00004: val_iou_score did not improve from 0.34529\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.66941\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.69364\n",
      "7070/7070 [==============================] - 1558s 220ms/step - loss: 0.6749 - iou_score: 0.3604 - val_loss: 0.6993 - val_iou_score: 0.3410\n",
      "Epoch 5/30\n",
      "6334/7070 [=========================>....] - ETA: 2:36 - loss: 0.6736 - iou_score: 0.3616"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "        generator=data_generator_train,\n",
    "        validation_data=data_generator_valid,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks_list,\n",
    "        workers=4,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-25T09:43:46.295Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax_loss, ax_iou) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax_loss.plot(hist.history['loss'], label='loss')\n",
    "ax_loss.plot(hist.history['val_loss'], label='val_loss')\n",
    "ax_loss.legend()\n",
    "\n",
    "ax_iou.plot(hist.history['iou_score'], label='iou_score')\n",
    "ax_iou.plot(hist.history['val_iou_score'], label='val_iou_score')\n",
    "ax_iou.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
